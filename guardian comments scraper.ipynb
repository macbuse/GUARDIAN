{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic scraping for Guardian discussions u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gregmcshane/GUARDIAN'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('guardian comments scraper.ipynb','r') as fp:\n",
    "    nb = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pp = re.compile(\"(https://www.the.*?)'\")\n",
    "lks = pp.findall(nb)\n",
    "\n",
    "with open('links.txt','w') as fp:\n",
    "    fp.write('\\n'.join(lks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import requests\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = 'https://www.theguardian.com/commentisfree/2020/aug/19/ditch-the-algorithm-generation-students-a-levels-politics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = my_keys.keys['guardian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting comments page no. 1\n",
      "there are 8 pages\n",
      "getting comments page no. 2\n",
      "getting comments page no. 3\n",
      "getting comments page no. 4\n",
      "getting comments page no. 5\n",
      "getting comments page no. 6\n",
      "getting comments page no. 7\n",
      "getting comments page no. 8\n",
      "archiving to etenk.pkl\n"
     ]
    }
   ],
   "source": [
    "#scrape the page and get the short url\n",
    "short_url_pp =  re.compile('\"shortUrlId\":\"(.*?)\"')\n",
    "\n",
    "r = requests.get(article_url)\n",
    "mm = short_url_pp.search(r.text)\n",
    "short_url = mm.group(1)\n",
    "\n",
    "#the short url allows us to access the discussion\n",
    "comments_url = 'https://api.nextgen.guardianapps.co.uk/discussion/%s.json'%short_url\n",
    "params = {'orderBy' : 'newest',\n",
    "          'pageSize' : 25,\n",
    "          'displayThreaded' : 'true',\n",
    "          'commentsClosed' : 'false',\n",
    "          'page' : '',\n",
    "          'maxResponses' : 50\n",
    "         }\n",
    "\n",
    "json_data =  []\n",
    "start_page  = 1\n",
    "last_page = None\n",
    "\n",
    "\n",
    "for num_page in range(start_page, 10**4):\n",
    "    print('getting comments page no.', num_page)\n",
    "    params['page'] = num_page\n",
    "    r = requests.get( comments_url, params=params)\n",
    "    json_data.append( r.text)\n",
    "    #The last page is a field in the json object\n",
    "    #I don't need to read this as json I could do a regexp\n",
    "    if num_page == start_page:\n",
    "        json_dict = json.loads(r.text)\n",
    "        last_page = json_dict['lastPage']\n",
    "        print('there are %d pages'%last_page)\n",
    "    if num_page == last_page : break\n",
    "        \n",
    "\n",
    "fn = '%s.pkl'%short_url.split('/')[-1]\n",
    "print('archiving to %s'%fn)\n",
    "with open(fn ,'wb') as fp:\n",
    "    pickle.dump(json_data,fp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-7a525c39f9dc>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-7a525c39f9dc>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    archiving to dqhaa.pkl #jenkins\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "json_data = pickle.load(open('dpb6e.pkl','rb') ) #jenkins\n",
    "\n",
    "archiving to dqhaa.pkl #jenkins\n",
    "\n",
    "archiving to evdjz.pkl #big cummings\n",
    "\n",
    "e9j7e.pkl # bragg\n",
    "\n",
    "eghyd.pkl # migrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pickle.load(open('etenk.pkl','rb') ) #jenkins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remember each page of comments has been stored separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = json.loads(json_data[0])\n",
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['postedCommentHtml', 'commentsHtml', 'commentCount', 'refreshStatus', 'lastPage', 'paginationHtml'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = json.loads(json_data[0])\n",
    "xx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<div class=\"d-discussion d-discussion--recommendations-open u-cf\"\n",
      "     data-read-only=\"false\" >\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print( xx['commentsHtml'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = re.compile('data-comment-author=\"(.*?)\"')\n",
    "pid = re.compile('data-comment-author-id=\"(\\d+)')\n",
    "\n",
    "auths = []\n",
    "for xx in json_data:\n",
    "    hh = json.loads(xx)['commentsHtml']\n",
    "    auths.extend(list( zip(pa.findall(hh) , pid.findall(hh)) ))\n",
    "\n",
    "auths = list(set(auths))\n",
    "auths.sort(key=lambda x : x[0].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auths = dict(auths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comment():\n",
    "    pass\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html2comments(x):\n",
    "    tt = json.loads(x)\n",
    "    soup = BeautifulSoup(tt['commentsHtml'],  \"lxml\")\n",
    "    raw = [ comment.text for comment in  \n",
    "            soup.findAll('div', {'class' : \"d-comment__body\"}) ]\n",
    "    \n",
    "    metadata = soup.findAll('span', {'class' : \"d-comment__author\"})\n",
    "    \n",
    "    auth = [x.text.upper().strip() for x in metadata]\n",
    "    auth_id = [ x.find('a')['href'] for x in metadata]\n",
    "    \n",
    "    return [ '##{}\\n{}\\n\\n{}'.format(a,b,c.strip())  \n",
    "                                 for a,b,c in zip(auth, auth_id, raw)]\n",
    "     \n",
    "all_texts = [ html2comments(page) for page in json_data[:] ]\n",
    "\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "all_comments = list(chain.from_iterable(all_texts))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('b7jtb.pkl','rb') as fp:\n",
    "    json_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [x.split('\\n')[0] for x in all_comments]\n",
    "from collections import Counter\n",
    "AN = Counter(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('##BJERKLEY', 45),\n",
       " ('##FATBOB', 41),\n",
       " ('##AJVC1991', 26),\n",
       " ('##SPIKE501', 20),\n",
       " ('##SKEPTICHAPPY', 13),\n",
       " ('##OLDWEASE', 13),\n",
       " ('##EASTONHALL33', 11),\n",
       " ('##JDRMCR', 10),\n",
       " ('##BREXITSBANE', 10),\n",
       " ('##HUGHBRYANT', 10),\n",
       " ('##NICCOLOFRANZORWELL', 10),\n",
       " ('##SNOWYJOHN', 9),\n",
       " ('##SWAN17', 9),\n",
       " ('##GEOFF001', 8),\n",
       " ('##FALLOWFIELD', 8),\n",
       " ('##FROMAGEBLEU', 7),\n",
       " ('##ALIEN98', 7),\n",
       " ('##FOSTER6THE6IMPOSTER6', 6),\n",
       " ('##CITIZEN_OF_EUROPE', 6),\n",
       " ('##TONDA99', 6),\n",
       " ('##SJAMES74', 6),\n",
       " ('##SEELIFEDIFFERENTLY', 6),\n",
       " ('##RHUBARBSONOFNECTAN', 6),\n",
       " ('##SHAKINGHEADSLOWLY', 5),\n",
       " ('##MISSILEMAN', 5),\n",
       " ('##ABBYLOX', 5),\n",
       " ('##WHATABOUTTHEFORESTS', 5),\n",
       " ('##CAVC66', 5),\n",
       " ('##SCUBADOC', 5),\n",
       " ('##KAVANGH', 5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(x,y) for x,y in AN.items() if y > 4], key=lambda x : -x[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments.sort(key=lambda x : -len(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##RJI777\n",
      "https://profile.theguardian.com/user/id/102379177\n",
      "\n",
      "The author might well be considered an expert on the subject of politics, but when it comes to \"algorithms\", \"predictive modelling\" and the recent \"statistical\" catastrophes, the article suggests that she lacks sufficient understand of the issues outwith her primary area of expertise.\n",
      "So, brief as it may be, perhaps the following might help:\n",
      "First: 1/ Algorithms, etc., apart, we lack the capacity to predict, with any certainty or consistency, the future in terms of an actual reality and all within which it is comprised;\n",
      "Second: 2/ Even if we could conquer 1/, our new found super powers would soon prove to be very restricted in terms of their use. This is because \"predictive modelling\" and the likes attempt to deal with rather large complex (sub) systems e.g., the UK, etc. Simply put, a key characteristic of complex systems is that they behave in all manner of counterintuitive ways which makes them, well, unpredictable;\n",
      "Third: 3/ To recap on 1/ an 2/: In very basic terms, we cannot predict the future and, even if we could, complexity restricts the application of this super power to only the simplest of problems.\n",
      "Four: 4/ To conclude, the A-level debacle occurred because someone, somewhere, probably not on their own, decided that a STATISTICAL algorithm could be used to solve the problem. Had they consulted a student studying A-level statistics, they would have been informed that statistical models are completely unsuited to any such task. They could also have checked the definition of \"statistics\" as defined by The Office for Statistics Regulation (OSR) in their Code of Practice for Statistics. In part, this reads: \"Statistics are used for making GENERALISATIONS or inferring conclusions about particular attributes, at an AGGREGATE level\" (p. 36); and, yes, I added the capitalisation; simply to draw attention to the use of statistics when generalisations at an aggregate level are required. That's where statistics can be really helpful.\n",
      "BUT NOT when the requirement is to provide individual students with an accurate set of grades, for each A-level exam that they would have sat, for every A-level candidate across the country.\n",
      "How dare they? Their arrogance is astonishing. Students are real people, unique individuals who live in the real world. They are not generalisations or aggregations; neither are the results they require. Hence, over and above 1/, 2/ and 3/, the mere suggestion that statistics might provide a suitable solution to this problem beggars belief.\n",
      "Have these people any idea how insulting they have been to their customers, the thousands of unique pupils, each requiring an accurate grade for each A-level exam that they could not sit, through no fault of their own?\n",
      "I mean, come on, it's hardly rocket science, is it? Complexity aside, we can't predict the future and statistics cannot provide a fit for purpose solution to this problem. As for the algorithm, well, ...\n",
      "..., you decide. I'm all angry again and must desist from writing any more. Apologies, but I have to go and lie down in a dark room for a while. I hope this helps.\n",
      "Be safe.\n",
      "\n",
      "##ATRUECLAREMANSSON\n",
      "https://profile.theguardian.com/user/id/16601866\n",
      "\n",
      "There is a massive fallacy at large. Algorithms are used every year in examinations. This is not the first year that they have been used. Predictive modelling and the use of statistics is present every year when boundary marks for each grade are established at the awarding meetings in examination boards. These statistical processes are 'algorithms' and they produce a 'statistically recommended boundary'. These are then generally accepted at awards meetings unless there are exceptional reasons not to do so. Teachers' estimated grades are noted but they rarely contribute to the final grades and every year thousands of grades (possibly hundreds of thousands) do not match the teachers' estimated grades. Because the external evidence of the examination paper is the final arbiter in disputed results the exam boards are in a very strong position as, under Ofqual guidance, less than 1% or so of re-marked scripts are changed.\n",
      "The problem this year was that there was no external evidence to support the final decision making as there is each year in awarding meetings. Therefore under appeal, an exam board could not challenge an estimated grade as there was no examination paper to fall back on. It was the lack of VALID evidence that blew apart the use of the algorithm.\n",
      "In the light of the above, there were actually only 2 rational routes available. Firstly declare all exams void for this year, which would have meant a devastating loss of time and energy for students and teachers alike: it was not a humane option. The second route was to declare an exceptional year status this year and issue all grades in full compliance with centre assessed grades (cag's). These grades could have been issued with a statement to the effect that due to exceptional circumstance, they were based on cag's only. The grades could also have been ready by mid to late June as the cag's were in the hands of the boards many weeks before. (Keeping to the historic mid-August release date was also an error that could have been avoided).\n",
      "This is effectively where we are now, and the chaotic mess of the last fortnight was a direct product lack of though and understanding in both government and Ofqual. I will leave others to comment on the government at this point. Ofqual, an organisation I have had some experience dealing with, is an organisation that pretends competence and insight where there is little. Their 'experts' are not experts as so many have not worked in schools or colleges. Ofqual likes to show to the world that it has a role because it has massive expertise (which isn't the case) and unfortunately in doing so this year they made catastrophic errors in using an evidence-based algorithm without valid evidence.\n",
      "\n",
      "##RJI777\n",
      "https://profile.theguardian.com/user/id/102379177\n",
      "\n",
      "As per my earlier post; not nearly as elegant as this, I might add; it is indeed a more fundamental problem.\n",
      "Algorithms have their uses, as does Statistics. However, by definition, Statistics takes input data and produces generalisations at an aggregate level e.g., to assist with decision making.\n",
      "Clearly, this is at odds with the need to provide 1,000s of unique, A-level candidates with accurate grades for each of the examinations they were never allowed to sit, through no fault of there own.\n",
      "Simply put, Statistics is not designed to do this. It's intrinsic data flow is typically in the opposite direction and cannot produce values for multiple real world data points, describing a large population of real world people.\n",
      "That requires a complement of real world processes (exam content and exam process), administered to and taken by a large population of unique real world people (A-level candidates) and then (referring back to exam process and content) graded by a population of qualified markers. Or similar, of course; but not using Statistics.\n",
      "Statistics can then be used to take these grades by subject by candidate and provide generalisations at an aggregate level, but not, under any circumstances, can Statistics produce this data in the first place.\n",
      "This is basic stuff. Ask anyone who had hoped to take an A-level in Statistics. They would know. In fact, a very bright young woman wrote a short award winning story about this very scenario (and got her A-level downgraded, despite the acclaim). Then again, why not look up the definition of Statistics?\n",
      "However, those involved in the various agencies did not. Neither did those in government. Why not? Did everyone involve miss the fundamental principles involved here? Who decided to do this? Why did no-one question this decision? Why did none of the MPs or domain experts point out that what was being proposed is sheer madness; never going to happen; breaking the bounds of the ridiculous; etc.\n",
      "More importantly, failing their customers; The A-level candidates. Insulted, patronised, etc.; not that those involved care. Arrogant to a fault; too busy blame shifting to admit to their mass incompetence.\n",
      "That said, there are no excuses; not this time. The \"I wasn't aware\" or \"I was reliably informed\" cards, were not dealt in this game. It's much simpler than that; literally a matter of schooling, or secondary education. In fact, it's pretty much a case of whack-a-mole; the mole being Statistics and the whacker being anyone who can define Statistics or, if they didn't, having the common sense to look it up.\n",
      "MPs? Algorithmic experts? The lot of them? Yeah, hang your heads in shame, because it really is shameful. Absolutely and unforgivable disgraceful.\n",
      "\n",
      "##PINKIE123\n",
      "https://profile.theguardian.com/user/id/15834048\n",
      "\n",
      "You’re right, but AI does not just abrogate responsibility, it abrogates personhood itself. \n",
      "Regarding religion, my point is that a state of pure atheism is virtually unobtainable - the reason being that such a state would be one of absolute freedom, which is impossible. In a strange sense, a certain species of doubting believer comes closest to atheism. For a modernist Christian such as Pascal or Kierkegaard, doubt in God is constitutive of God. For these thinkers, man is free to the extent that God withdraws his authority. The further he withdraws, the greater the need for faith. The greater the faith, the greater the doubt. That is, for the post-Cartesian subject, doubt in the ground if its own being is constitutive of itself as a free, independent moral agent. \n",
      "To attain something close to atheism, one has to pass through belief. Moral responsibility is a concept that derives from belief. Why can’t belief be dispensed with entirely? Because then one would find oneself in the impossible position of being the God one is not. \n",
      "The religious impulse cannot be eradicated. We always seek an authority external to ourselves - in history, science, AI, whatever. The best we can do is doubt - to act as if we are free even if we are not truly so. \n",
      "In contrast to a personhood of moral responsibility, AI promises the full integration of the human into a technological universe of pure, deterministic calculation - negating human existential and moral freedom. This is not faith, it is fundamentalist certainty, and therefore much more religious than much ‘religion’. \n",
      "In sum, the best we can do is create a distance between whatever our ground of authority happens to be and ourselves. In a true theocracy there are no believers. A medieval peasant did not believe that the King had been ordained by God, it simply was so. Similarly, many people don’t believe in the decisions made by computers, they just accept them. You do not know you are part of such a metaphysic when you are immersed in it. Our metaphysic is that our brains are computers and the world is made of bit of information. Despite the empiricist language - BECAUSE of the empiricist language - we accept what is no less a theological construction than medieval cosmology.\n",
      "To have faith is to step out of the theological order and doubt what is experienced as a given.\n",
      "\n",
      "##PINKIE123\n",
      "https://profile.theguardian.com/user/id/15834048\n",
      "\n",
      "Ditch the Algorithm is a great slogan.\n",
      "The important point is as follows: The algorithm does not express its own intrinsic rationality, independent of human concerns. It is encoded with the values and political intentions of its creators, embedded into their structures of power. And because the algorithm expresses human decisions in the disguise of trans-human rationality, democratic accountability for those decisions is negated. \n",
      "A medieval monarch would claim to act on behalf of God while not letting on that this God is his own invention and a proxy for his own power. Authorities of today claim to act on behalf of AI in similar fashion. AI is just another God - another deity we have created to serve our own purposes and then worship as though we had not, as though it has power over us. \n",
      "The difference is that while the Christian God (from the Reformation at least) required faith and therefore allowed doubt, the algorithmic God permits none (in a strange sense, the doubting Christian is closer to atheism than the person who believes in AI). What is striking about the algorithmic order is that it is the most fundamentalist of religions while presenting as pure, secular rationality. For proof, look to the extremes - to the techno-millenarian eschatological cults that pervade the internet.\n",
      "The basis of our politics should be that humans have an array of needs. If these needs are met, humans can flourish. Politics, markets, technologies and bureaucracies should exist to serve the fulfilment of these needs. Things go very wrong however when the logic reverses and instead of these things serving us, we serve then. Then the state is not there to serve people but it is people who serve the state. Or equally market does not exist to serve people but it is people who serve the market. And in the emergent power order, computers do not exist to serve humans but humans exist to serve computers.\n",
      "Important point: there is nothing intrinsically wrong with computers. To accord them an inherently negative moral quality is a different side of the same coin, denying human agency. They are, for good or ill, merely the tools we have created. It is the purposes to which they are put that must be interrogated, not the fact of themselves - which is neither here nor there.\n",
      "\n",
      "##GORDONFREEMANK\n",
      "https://profile.theguardian.com/user/id/14315576\n",
      "\n",
      "The problem is that there's more to AI-driven decision making that just algorithms. Essentially you have two parts in a machine learning process: a machine learning algorithm, and data for the algorithm to be trained on. The combination of those two things creates a model that you can then apply to new information.\n",
      "The issue with this is that it doesn't matter how good your algorithm is, if your training data is rubbish. And the problem is that the training data will always be rubbish, because it's stuff that is in the past, and as such, integrates all the biases of the past that we want to get rid of in the first place!\n",
      "What happened with the Ofqual algorithm perfectly showcases the problem: the training data is last year's results, which includes countless implicit biases, because of course last years' results (and the years before that) are littered with biases around income, race, etc, which is generally summed up in the term \"postcode lottery\".\n",
      "Now you could try to fix that by adding bias to your algorithm (you could call it \"correct the bias\"), but then what the articles rightly points to is that then your problem is just displaced, and the debate will then move on to the legitimacy of that bias correction (which will essentially be akin to positive action) and how to calculate the bias correction in the first place.\n",
      "For instance, obviously your income will influence your results. And you want to say \"I want the amount of work someone puts in to be the only influencer of the results\". That sounds fair, but isn't the amount of work you are able to put in school also dependent on income? i.e. if your parents are richer, you are more likely to have more structure, e.g. your own room hence more likely to be able to work hard. One could argue that ultimately if you correct all the biases, you'll end up giving the same grade to everyone!So to an extent, maybe the key is to ban ML in political decisions in the first place, and use actual critical thinking instead. You can still use statistics for that!\n",
      "\n",
      "##MALACHICONSTANT\n",
      "https://profile.theguardian.com/user/id/2632806\n",
      "\n",
      "In this case, Ofqual’s model decided it’s not possible that good teaching, hard work and inspiration can make a difference to a young person’s life and their grades.\n",
      "\n",
      "No, Ofqual, don't believe those things are unimportant, they just didn't have any data on whether individual students had been well taught, worked hard, or were inspired. That is what the exams were supposed to provide, and the exams weren't given. Exams, by the way, are also just \"algorithms\", just rather more complex ones where you first set a paper and then students answer the questions under controlled conditions and then you mark them and rank the results. That couldn't be done, and yet it was decided that students must have individual grades. The only people with sufficient data on individual students were the teachers, so they were asked to supply predicted grades. You then have a choice - you can accept those grades, which are unrealistically inflated compared to any realistic prediction of what the average results to the real exams would have been. Or you can adjust those grades based on some more global data, knowing that those adjustments would inevitably be unfair to some individual students who would have overperformed relative to your prediction. The first method is deeply unfair to the students in the other years (just wait until the screams next year when the number of places in the top universities is greatly reduced because of the need to fit in all the extra students deferred from this year), the second method is deeply unfair to some students in this year. The government first decided to be fair across years, then under pressure they switched to trying to be fair within year, and as a consequence they have made everyone angry and left a giant mess that will need years for the universities to sort out. None of that is because there is something inherently evil about algorithms, it is because the government cocked this one up (and then cocked up sorting out their cock up).\n",
      "\n",
      "##THEHARPER\n",
      "https://profile.theguardian.com/user/id/3780738\n",
      "\n",
      "Fair enough but as they didn't get to sit exams, what about human bias in setting grades?\n",
      "Contrary to much popular mythology in the GU, Teachers like Nurses are in fact not Angels but human, with all the frailties that come with it.\n",
      "How often have people remarked on so and so being a good or great Teacher - i.e. they're a mixed bag!\n",
      "Attainment as expressed by grades is a reflection of Teaching quality. So if you know you're a bit shit, there'd be a temptation to be, say, optimistic in assessment of grades, no?\n",
      "Also, being human, they're not going to take a shine to every pupil, are they? So bias, even if sub-conscious, can occur because they actually like the individual, think they are deserving, worked hard etc... The other end of the spectrum, would be the bright but lazy and disruptive pupil.\n",
      "Don't know anything much about the flaws of this specific Algorithm but in theory, at least, providing the data input is robust. Then surely should be less wonky than leaving it to the individual Teacher. Ditching them as a result of these exceptional circumstance seems a bit backward.\n",
      "Feel for the pupils awaiting grades, it'll feel like life or death to some. That, however, stems from the ridiculous pressure put on academic achievement at such a tender age. They do not chart the chance of a successful career for the rest of your life.\n",
      "These days, you can go back to education anytime in your life. Easy to look back now and laugh at how much store was put on Grades. The more I think about it, the more education seems wasted on the young. Mature Students, on average, do better than those entering higher education in their teens.\n",
      "There's just so much going on in your teens, with hormones rampant and insecurities galore, to concentrate on studies or face judgement by Grades.. Be better to take a break, go do something worthwhile like harvesting our crops and go back to education in your 20's when your mind and body are more settled.\n",
      "Bit too radical, that one, I reckon?\n",
      "\n",
      "##ABBYLOX\n",
      "https://profile.theguardian.com/user/id/17217284\n",
      "\n",
      "Section 8.4 (Centres with a small entry in a subject) in the link below discusses the issue in depth. The short answer is that the primary aim was to use historical data to remove variations between schools so that the results were comparable. For small number of students this wasn't possible so the teacher predicted grades were used instead as there was no other option. It was acknowledged that this would be expected to lead to higher grades in those cases but no suitable alternative was identified.\n",
      "https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/909368/6656-1_Awarding_GCSE__AS__A_level__advanced_extension_awards_and_extended_project_qualifications_in_summer_2020_-_interim_report.pdf\n",
      "\n",
      "One of the principles on which the standardisation approach was based is that more weight should be placed on the statistical historical evidence of centre performance (given the prior attainment of students) than the submitted CAGs (see Section 4.2). The motivation for this decision is to ensure that any residual leniency or severity in the CAGs is removed equally across centres reducing inter-centre unfairness and to ensure that any overall leniency (which is likely to arise from a tendency towards leniency in the CAGs) is handled in a way that does not advantage or disadvantage centres who have taken different approaches. The consequence of this decision is that, in the majority of cases, the statistical model will be applied to determine the grade distribution for each centre in each subject. \n",
      "An intended exception to this situation was for centres with a small number of entries in a subject. This reflects the weakening of the statistical evidence as the number of students reduces. In these circumstances, it is necessary to move from the statistical evidence as the primary source of evidence to the CAGs.\n",
      "\n",
      "##DUNE1959\n",
      "https://profile.theguardian.com/user/id/3318890\n",
      "\n",
      "It's also absurd to suggest teachers are incapable of the same bias and discrimination that pervades the rest of society.\n",
      "\n",
      "The implication of the above is that all teachers do is stick their finger in the air and whatever grade they come up with goes. This is far from the truth.\n",
      "There is a moderation process and having worked as a moderator I can assure you there is zero incentive to allow through obviously over inflated outcomes. \n",
      "What is absurd is to imply there isn't a professional approach to this that sets out to minimise error and that there is no effort to try an eliminate any such bias.\n",
      "You are coming from a stance of (essentially) that everyone is corrupt. Just because you see that in one sector of society (Tory politicians being the prime example) doesn't mean professions like teaching have thrown ethics and professionalism out of the window and they don't have systems and procedures in place to minimise bias.\n",
      "If you go to the Ofqual website you can read what procedures teachers must go through to predict grades. It's not trivial. The fact we then ended up with them being ignored to the extent they were undermined in some schools but left to stand in others based on stupid algorithmic rules is a far bigger issue than the problem you incorrect perceive to a major issue, that if inherent bias. The inherent bias was was in the bloody algorithm.\n",
      "As to Labour's stance in 2019 you are missing the point. Predicted grades where state school pupils were predicted (say) BCC compared to AAA from private was denying the OFFER of a place. Today we are looking for mechanism to AWARD grades to students who ALREADY have places. Predicted grades are not perfect, no one is arguing they are but they are a better mechanism than an algorithm that downgrades 40% of predictions.\n",
      "\n",
      "##MOZARTKUGELN\n",
      "https://profile.theguardian.com/user/id/18301742\n",
      "\n",
      "The big question is who gets to use algorithms and for what purposes should they be used? Once governments start using them, especially when data has not been openly gathered, then imho we getting into dangerous territory.For example, algorithms that predict which children might be at risk of abuse, which visa application should be denied, or who has the greatest probability of committing a crime. Our life chances – if we get a visa, whether our welfare claims are flagged as fraudulent, or whether we’re designated at risk of reoffending – are becoming tightly bound up with algorithmic outputs.In an earlier piece in the Guardian, Huy Duong who came to the UK as a teenager with his parents in the 1980s, a refugee from communist Vietnam predicted the fiasco of the Ofqual algorithm: standardisation would result in 39% of students being downgraded, with disadvantaged pupils worst affected. He told the Guardian that his formative years in a Communist regime made him inherently opposed to anything which felt opaque and undemocratic. And that included “collective punishment by statistics”.Let's pause and consider how say the PRC might use algorithms.Maybe, had the students sat exams this year many would have accepted the usual workings  of algorithms (they have been used by Ofqual and exam boards for years to give tye government the results, not the true results but the results which are acceptable and expedient to the Minister of Education. However some planet-sized brain didn't see that the algorithm could cause big problems when students didn't sit exams. So imho this fiasco has done us a favour by shining light on the algorithmic dark practices. They may have their uses and benefits but once they become tools of government and authority, beware.\n",
      "\n",
      "##WOZEARLY\n",
      "https://profile.theguardian.com/user/id/16310402\n",
      "\n",
      "Eastonhall, several of your points are entirely valid if you look at the system as a whole, but the difficulty comes when you have to decide what standardisation to apply at individual level (ie, whose grades do you actually reduce and why), and what the process is where some (and potentially all) of those individuals challenge it, but no-one will challenge (or accept regrading) if their results are as high or higher than predicted. Surely you're not arguing in favour of the algorithm as the right solution to this?\n",
      "That teacher predictions are inaccurate, and that they erred on the side of considering a student's realistic potential rather than likelihood of what might happen on exam day (where even good students can slip down a grade), is accepted. It would have been quite problematic to ask them to predict otherwise. \n",
      "Agreeing to correct down results based on a school's past performance is a somewhat logical approach to addressing that gap to avoid grade inflation, but falls down when you have to decide which individuals would actually do worse if they were to sit a hypothetical exam they didn't sat. Slipping a grade or two because you struggled in the exam is something people can accept - having an algorithm decide that it reckons you would have done without providing evidence at individual level is not something anyone was going to accept.\n",
      "Obviously, given a free choice the students would prefer whichever approach resulted in higher individual grades. But the algorithm was never going to be an acceptable answer if it had to modify down a large number of grades with limited possibility of appeal. It's astonishing it was the official solution, and that these flaws weren't spotted much earlier on.\n",
      "\n",
      "##DUNE1959\n",
      "https://profile.theguardian.com/user/id/3318890\n",
      "\n",
      "'The metric took no account of how hard a school had worked..'. \n",
      "Why should it?\n",
      "Exam grades are meant to measure achievement, not effort.\n",
      "\n",
      "\n",
      "Why should it not? \n",
      "When the measure of achievement is a grade in an exam and there are no exams how do you dish out grades to give that measure of achievement? What factors do you take into account to come up with the grades? \n",
      "You are arguing the effort teacher put in to get their students the best grades they could should be ignored.\n",
      "What Ofqual chose to do was ignore the advice of teachers on what they believed their pupils level of achievement was, which in some cases would be an improvement on mock results and overall for some schools represent an improvement overall in the schools performance. \n",
      "Given schools improving performance is a government requirement an algorithm that bakes in the assumption they had not improved is simply biased.\n",
      "To put things in context:\n",
      "\"The Ofqual algorithm was the technical embodiment of a deeply political idea: that a person is only as good as their circumstances dictate. The metric took no account of how hard a school had worked,....\"\n",
      "So as there were no exam papers to grade other factors were plugged into an algorithm to decide the \"measure of achievement\" you mention.\n",
      "What the quote is saying is that the algorithm was based on flawed data, as in they come from a school that's previous record was poor so they were bound to be poor achievers, and made an assumption on students achievement based on that flawed data. That trumped any data form teachers.\n",
      "So that is what is meant by how hard the school hard worked as in how hard it had worked to improve the students. It was assumed this was completely impossible!\n",
      "\n",
      "##FOSTER6THE6IMPOSTER6\n",
      "https://profile.theguardian.com/user/id/3715976\n",
      "\n",
      "Fair enough but as they didn't get to sit exams, what about human bias in setting grades?\n",
      "(I meant to post this, but posted it elsewhere...I am all over the show today!)\n",
      "Thank you for your detailed thoughts. Actually having spent most of my working career in HE I know very well that teachers and insitutional culture, will both demonstrate bias. And I recognise that adopting a general linear model (GLM) using population data, one can weight in and out the effect of these things. And of course, that solves the problem at the level of population statistics.\n",
      "But the cost is too high for this type of task. It is as simple as that. You see if I select a student from a given college and say they should be down graded because generally people at that college are over marked, I am ignoring this individual, and their work. If the marker is over marking then that is something that should be dealt with by effective moderation, using objective marking criteria (which students are aware of in adavnce).\n",
      "We should not treat people as if they are a faceless example of everyone...for transparency and fairness, a students work should be graded as fairly as possible, by a marker/assessor, and given a grade. If markers demonstrate excessive bias, then moderators should be working with them to ensure work is meeting marking criteria. And I think here is the problem...this year that will not have been possible. However, that does not mean it is okay to adjust grades using population data.\n",
      "I may be male...the average age of death for a male is 76. If I am lucky enough to live to 77, I am very much hoping no one comes along to adjust my life span to the correct amount for my group!\n",
      "\n",
      "##RPDOLAN\n",
      "https://profile.theguardian.com/user/id/4041014\n",
      "\n",
      "There is a useful term for examining the data from a computer system. It's GIGO - garbage in /garbage out. The algorithm used to calculate exam results, was based on the human perception of what was useful information to put in the system. Not taking into account the effect on very small class sizes on the results ( ie favouring private schools) meant the information into the algorithm was already flawed. Also using the previous performance from schools is also subject to error ie past performance is being used in a speculative context. This happens in horse racing where you might back a horse because it won its last three races. Yet the horse doesn't always win the next race and a horse with a poor record might win. This is called gambling. The odds might be very good on a school getting a certain result, but it is just a refined form of gambling. Now teacher assesments of grades can be classified the same way, yet crucially they have more personal information on which to base an assessment, and can factor that in. Therefore while teachers grading is not ideal, nothing is compared to an actual exam, they have more information on which to award a grade. There is a reasonable fear that some teachers might be more generous in their marking than they should be, yet that bias happens within the school system anyway, We all have teachers we felt treated us unfairly, and marked us down out of political bias, nationalistic bias, or simply because they didn't like us. Yet outside the actual exams there is no ideal way of grading students, except in the hope that as in most cases teachers are professional enough to fairly assess their students.\n",
      "\n",
      "##FALLOWFIELD\n",
      "https://profile.theguardian.com/user/id/2968301\n",
      "\n",
      "Over a week ago when it was leaked that 40% of results were going to be downgraded, some of us knew who that would affect, and it wasn't going to be Etonians. We were on the money.This is nothing new. Those who advocate selective state education, usually relying on the 11+ as the fairest way to allocate places, should be aware of two competing systems of assessment. They are norm referencing and criterion referencing.A crierion based system fits in with common sense. You get the pass mark, say 70%, you pass the exam with a high grade. But that's not how it works. In the much more usual norm based system your mark is compared to those of eveyone else. If a load of them did better than your measly 70% you are pushed along the bell curve, the normal distribution, into a lower grade band. In other words, you are not being judged by your own merits and abilities, you are in the line-up of a beauty contest, and there can only be one winner and two runners up.One of the many criticisms of the 11+ was that it discriminated against girls. How could that be? Girls went to grammar school in the same number as boys - but that was the problem. Girls, on the whole, did better than boys in the exam, got higher marks. Therefore there should have been more girls than boys in the grammar schools, but that was politically unacceptable.This would have been a possibility: twin brother and sister, same primary class, took the exam. He scored 65%, she scored 69%. He went to the grammar, she went to the sec mod. It is important to realise that nobody knew what their actual mark was.That is how norm referencing works.\n",
      "\n",
      "##FOSTER6THE6IMPOSTER6\n",
      "https://profile.theguardian.com/user/id/3715976\n",
      "\n",
      "Fair enough but as they didn't get to sit exams, what about human bias in setting grades?\n",
      "\n",
      "Thank you for your detailed thoughts. Actually having spent most of my working career in HE I know very well that teachers and insitutional culture, will both demonstrate bias. And I recognise that adopting a general linear model (GLM) using population data, one can weight in and out the effect of these things. And of course, that solves the problem at the level of population statistics. \n",
      "But the cost is too high for this type of task. It is as simple as that. You see if I select a student from a given college and say they should be down graded because generally people at that college are over marked, I am ignoring this individual, and their work. If the marker is over marking then that is something that should be dealt with by effective moderation, using objective marking criteria (which students are aware of in adavnce).\n",
      "We should not treat people as if they are a faceless example of everyone...for transparency and fairness, a students work should be graded as fairly as possible, by a marker/assessor, and given a grade. If markers demonstrate excessive bias, then moderators should be working with them to ensure work is meeting marking criteria. And I think here is the problem...this year that will not have been possible. However, that does not mean it is okay to adjust grades using population data.\n",
      "I may be male...the average age of death for a male is 76. If I am lucky enough to live to 77, I am very much hoping no one comes along to adjust my life span to the correct amount for my group!\n",
      "\n",
      "##CITIZEN_OF_EUROPE\n",
      "https://profile.theguardian.com/user/id/101220304\n",
      "\n",
      "The problem is not the use of algorithms per se, but the judgement of whether a particular algorithm is fit for the purpose to which it is being put. Algorithms have the advantage of giving unambiguous answers and in one sense are objective, in that once put in operation the user cannot influence the outcome.\n",
      "The problem in this case is that the algorithm is designed to maintain a consistent standard in terms of average and spread from one year to the next. Because it is based on the statistics that it is intended to maintain, it is effectively inevitable that it will achieve its purpose, which is of course why it is utterly useless for giving individual pupils a fair assessment - that would allow unique achievement to undermine the principle of maintaining the standard.\n",
      "There is nothing new in this in education, although the process has got steadily worse over the last ten years - since Michael Gove linked individual teachers' pay directly to pupil performance. A lot of private companies (\"charities\" they like to call themselves), and one in particular which had Gove's ear, have cashed in by offering the sector measures of what pupils should achieve based on past performance (even back to age 4!) and teachers are then held to account on that basis. Anyone with a modicum of mathematical sense knows that it is complete BS, but because it works on \"average\", these companies continue to make their exaggerated claims as to the precision of their algorithms - while knowing they are used in way for which they were never designed.\n",
      "\n",
      "##SNOWYJOHN\n",
      "https://profile.theguardian.com/user/id/11657695\n",
      "\n",
      "Downgraded compared to what?\n",
      "\n",
      "To help with university admissions, etc. students are given predicted grades by their schools well in advance of them taking the exams. These are based on teacher assessments and mock exams taken during the course. \n",
      "In the absence of final exams being taken this year, the examination body took the predicted grades for students and then applied factors based on what the school had previously achieved to level them out and ensure schools weren't overpredicting. This meant that in a lot of cases students ended up with significantly lower grades than they had been predicted, because of the adjustment. \n",
      "You could argue that on a meta level, that's kind of the best way to do it, as it suggests grades may have been over-predicted in some schools, but you'd still be gutted if you lost a university place because the exam board decided your school was shit so there was no way you were going to get the good grades you were predicted...\n",
      "Also, there are numerous issues that have been raised with how the system worked. e.g. some independent schools with small class sizes were not subjected to same algorithm, so teachers' grades were accepted without question. Also, there are questions about how it's been implemented. This blog is interesting. It suggests that in the case of one school, someone got lumbered with a U (i.e. unclassified, which is a terrible result) despite the numbers not supporting that, whilst they should arguably have had more top results.\n",
      "\n",
      "##BJERKLEY\n",
      "https://profile.theguardian.com/user/id/1380347\n",
      "\n",
      "The whole issue was how to correct for teacher assessment in fact.\n",
      "\n",
      "Not really, since teacher assessment was relied upon for large cohorts in terms of ranking but otherwise played no part in the decision making. And I think it's just unsustainable to say that the point was to correct for teacher assessment when certain cohorts were excluded from that process altogether.\n",
      "\n",
      "I don't fully understand what you mean with your second point.\n",
      "\n",
      "By way of an example: A cohort could have 5 A students and one U student in each of the historic years for standardisation. In this year, they could have 5 A students and one B student and yet the B student would be awarded a U under the standardisation process.\n",
      "Worse, you could have a situation where statistically 0.5% of students in a cohort got a U and 0.5% an A*, but under this system, one would be given a U but none an A*. Downgrading was baked into the system unnecessarily.\n",
      "\n",
      "With your last point...how do you know that a result is unfair or odd? And if you appeal, how do you resolve the appeal?\n",
      "\n",
      "Some results would be clear enough. Let's say someone was a B student in GCSEs and consistently got Bs in their course work and mocks. If they then ended up with a D, I think it would be difficult in good faith to say that getting a result they never got previously for an exam they didn't take isn't unfair to that student.\n",
      "And the appeal could be based on showing that disparity and looking at why they were assigned such an outlier grade.\n"
     ]
    }
   ],
   "source": [
    "print( '\\n\\n'.join(all_comments[:20]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/gregmcshane/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '''My views haven't changed. Leaving the EU will be of no benefit to anyone except those who hold money and power along with certain corporates and a smidgen of medium to small businesses.\n",
    "How else can it be when you are shutting shop to the most developed nations, the richest nations in the world, who are either in the EU or have market agreements with the EU. Even the emerging markets of China and India along with other developing economies are aspiring to develop trading agreements with the EU, the second largest economy in the world. Any deal with the UK will be secondary and will depend upon their agreement with the EU.\n",
    "Boris Johnson once said \"f**k business\". I take this as meaning there is something in it for them and they don't really care if businesses find it difficulA\n",
    "t to cope.\n",
    "I can see ministers and conservative MPs queuing to fill their pockets by acting as advisors for potential trade deals whilst the rest of the country are left struggling trying to rebuild their lives, especially following the pandemic. The same ministers will probably be looking to lower all kinds of standards from food and welfare to safety at work to improve their opportunities.\n",
    "When it comes to brinkmanship, I can only view this as getting away with whatever they can. I do not believe it is anything to do with negotiating an agreement that will be to the benefit of the UK or the EU as a whole, I don't believe our ministers are capable of doing that.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sentiment_valence() missing 4 required positional arguments: 'sentitext', 'item', 'i', and 'sentiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6f3326dcf5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_valence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sentiment_valence() missing 4 required positional arguments: 'sentitext', 'item', 'i', and 'sentiments'"
     ]
    }
   ],
   "source": [
    "sid.polarity_scores(a)\n",
    "sid.sentiment_valence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##CITIZEN_OF_EUROPE\n",
      "https://profile.theguardian.com/user/id/101220304\n",
      "\n",
      "The problem is not the use of algorithms per se, but the judgement of whether a particular algorithm is fit for the purpose to which it is being put. Algorithms have the advantage of giving unambiguous answers and in one sense are objective, in that once put in operation the user cannot influence the outcome.\n",
      "The problem in this case is that the algorithm is designed to maintain a consistent standard in terms of average and spread from one year to the next. Because it is based on the statistics that it is intended to maintain, it is effectively inevitable that it will achieve its purpose, which is of course why it is utterly useless for giving individual pupils a fair assessment - that would allow unique achievement to undermine the principle of maintaining the standard.\n",
      "There is nothing new in this in education, although the process has got steadily worse over the last ten years - since Michael Gove linked individual teachers' pay directly to pupil performance. A lot of private companies (\"charities\" they like to call themselves), and one in particular which had Gove's ear, have cashed in by offering the sector measures of what pupils should achieve based on past performance (even back to age 4!) and teachers are then held to account on that basis. Anyone with a modicum of** MATH**ematical sense knows that it is complete BS, but because it works on \"average\", these companies continue to make their exaggerated claims as to the precision of their algorithms - while knowing they are used in way for which they were never designed.\n",
      "\n",
      "##TAKENISTHIS\n",
      "https://profile.theguardian.com/user/id/17256959\n",
      "\n",
      "The problem isn't algorithms, the problem is the good old arts/science divide. The top of this country, including government, is dominated by arts/humanities grads. When it comes to science and anything scientific, they tend to two wild extremes.\n",
      "The first is to condemn all science and put their faith in new age woo. Stuff like homeopathy and other non-sense. When challenged about this, they claim their lack of knowledge as a form of expertise and a badge of pride. \n",
      "The second reaction is a modern form of the cargo cult. They don't really understand science and** MATH**s but treat it like some omnipotent god, capable of magically solving all problems. New Labour's obsession with big IT projects is a good example of that. With the added bonus of being able to evade all responsibility for decisions because the algorithm told us to do it.\n",
      "The reality is AI,** MATH**ematical models and computer algorithms are just tools. A bad workman blames their tools or as my engineering professor use to put it. Garbage in garbage out.\n",
      "We shouldn't turn against algorithms, big data and more evidence way of running government. We just need to have people at the top who understand how to use these tools and we, as you say, need the methodology used to be open and transparent.\n",
      "\n",
      "##EMILYISOBEL\n",
      "https://profile.theguardian.com/user/id/3632120\n",
      "\n",
      "The use of statistical algorithms to determine outcomes for individuals, whether that’s by exam boards, the home office, the DWP or the NHS, shows that the people in charge do not understand the** MATH**ematical principles of statistics and large datasets. Big data can be useful to give indicators as to whether policies are effective overall, or where funding is most needed, but should never be applied to individuals as people are extremely variable on an individual basis - there is no such thing as an average individual.The obsession with profiling and fitting people into groups is something that the right wing accuse the left of doing, but the use of big data to categorise and control people and entrench inequality is widely used by the right, whether by government or by right wing commentators to demonise people who want to change the stranglehold that polluting industries have or who want to overturn structural prejudices that stop people from having true equality of opportunity.\n",
      "\n",
      "##THEBEARD\n",
      "https://profile.theguardian.com/user/id/853401\n",
      "\n",
      "I haven't seen any explanation of the purpose of the algorithm as yet, so I'm going to suggest a possibility;\n",
      "- in school A, every year the** MATH**s department makes predictions of A level grades. Those predictions are made in order to support early allocation of University places. Unfortunately, whether wilfully or accidentally, school A has a 10 year history of over-predicting grades by 10%. The algorithm seeks to normalise this bias.This is only required this year because the exams didn't take place. In normal years, the students would be disappointed because they didn't achieve their predicted grade. This year, the actual grade accurately reflects what the student would have got had they taken the exam but it's now \"the fault of the algorithm\". Normalising the results this year makes sense as it then does not penalise students whose teachers happen to be better at predicting A-level grades.\n",
      "\n",
      "##JOHNOFBATH2015\n",
      "https://profile.theguardian.com/user/id/15017962\n",
      "\n",
      "Algorithms are Mathematical models. Inherent in every** MATH**ematical model are assumptions. These would include which factors are important and what weighting should we give to the factor, how the factors interact and so on. Get the assumptions wrong and the algorithm is less useful.\n",
      "But the big question is not about the algorithm, it is about the teachers’ assessments. If the number getting higher grades is valid, this year’s students must be significantly cleverer than previous years. Is this true? Has anyone looked at the actual work? Are course work marks usually of a higher than exam marks? Where universities warned of enormous grade inflation so they could have adjusted their offers? \n",
      "So many questions. Keeping an eye on those is the job of government, but Gavin and his Spads and disillusioned civil servants did not ask until it was too late.\n",
      "\n",
      "##SPIKE501\n",
      "https://profile.theguardian.com/user/id/4632941\n",
      "\n",
      "Are you honestly trying to claim code comes ex nilho or that its not possible to have bias algos?\n",
      "\n",
      "No, I never claimed that - I stated that your claim that algos are as biased as the people that write them. In other words you claim was the opposite of the words that you above put in my mouth.\n",
      "Some algorithms may have some bias from those that write them in, more regularly there may be some bias from the underlying data, but this is nothing to do with the bias of the people that write the algorithm\n",
      "\n",
      "The statistical probabilities themselves need to be written into code\n",
      "\n",
      "How do they need to be written in? The statistical probabilities are an output not an input and no one needs to design linear regression, its a** MATH**ematical formula, any more than someones bias can influence the outcome of 2+2.\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "This algorithm actually probably was fair. Unfortunately, it was fair at a population level - ie the grades awarded were in line with expectations for the population as a whole compared to previous years. It was actually the teacher assessments that weren't fair (the teacher assessed grades are clearly inflated). But obviously the fact that the nationwide result was statistically about right isn't any consolation to the individual kids. That's the problem with trying to** MATH**ematically model human destiny...it is going to piss people off, and rightly so. \n",
      "One obvious and very easy thing to fix is the stupid idea that university places be offered on predicted grades rather than actual grades. I fail to see the logic in this day and age especially. The process can be expedited pretty quickly.\n",
      "\n",
      "##1LOVE1HEART\n",
      "https://profile.theguardian.com/user/id/100796168\n",
      "\n",
      "Why 'Ditch the algorithm' is the future of political protest\n",
      "*\n",
      "Political: \n",
      "late Middle English: from Old French politique ‘political’, via Latin from Greek politikos, from politēs ‘citizen’, from polis ‘city’.\n",
      "Algorithm: \n",
      "late 17th century (denoting the Arabic or decimal notation of numbers): variant (influenced by Greek arithmos ‘number’) of Middle English algorism, via Old French from medieval Latin algorismus . The Arabic source, al-Ḵwārizmī ‘the man of Ḵwārizm’ (now Khiva), was a name given to the 9th-century** MATH**ematician Abū Ja‘far Muhammad ibn Mūsa, author of widely translated works on algebra and arithmetic.\n",
      "In sum, politics belongs to the people and algorithms belong in** MATH**ematics.\n",
      "They should not be mixed.\n",
      "\n",
      "##ONENATION2\n",
      "https://profile.theguardian.com/user/id/10932291\n",
      "\n",
      "Problems occur when people lose sight of the fact that models are exactly that: models.\n",
      "The accuracy with which model emulate or describe reality somehow often gets over looked and outcomes predicted by a model are mistaken for outcomes that would be found in reality.\n",
      "Models often amount to little more than collections of** MATH**ematical expressions and devices that can be and often are further reduced to numbers and arithmetic. There's a need to be wary of allowing these numerical processes to shape our reality.\n",
      "We reduce the the way that we interact with one another to numbers at our peril. We're much more than just numbers.\n",
      "\n",
      "##MORERATIONAL\n",
      "https://profile.theguardian.com/user/id/10558576\n",
      "\n",
      "The branch of** MATH**ematical statistics that is appropriate for this kind of grade analysis is known as 'multilevel analysis'. It is well established. It is obvious that once the A-level results had been computed by the algorithm, a thorough analysis should have been conducted in order to assess why there were so many seemingly anomalies. The Government should have held back publication until an understanding of the results had been obtained and it should have concluded that the methodology used was NOT suitable enough and gone for teacher grading instead.\n",
      "\n",
      "##MORERATIONAL\n",
      "https://profile.theguardian.com/user/id/10558576\n",
      "\n",
      "The branch of** MATH**ematical statistics that is appropriate for this kind of grade analysis is known as 'multilevel analysis'. It is well established. It is obvious that once the A-level results had been computed by the algorithm, a thorough analysis should have been conducted in order to assess why there were so many seemingly anomalies. The Government should have held back publication until an understanding of the results had been obtained and it should have concluded that the methodology used was suitable enough and gone for teacher grading instead.\n",
      "\n",
      "##VOICEOREASON\n",
      "https://profile.theguardian.com/user/id/3855284\n",
      "\n",
      "“Ditch the algorithm” protests from a bunch of Art students? Huzzah. Perhaps if they had a better grounding in Maths they would be in field able to directly influence and change things rather than simply protesting another thing they are incapable of comprehending. Algorithms need far more rigorous oversight but they are here to stay, if only because the bulk of the protesters have no idea what they are protesting besides “algorithms = bad.”\n",
      "\n",
      "##EVERYBODYELSE\n",
      "https://profile.theguardian.com/user/id/3431995\n",
      "\n",
      "That the end-results were discriminatory as a result of this** MATH**ematical easement seems to be of little import to you. It's hugely clear to those who gained and those who lost as a result. Defending its use by such a lazy, incompetent government as this and arguing the** MATH**ematical merits of its design over individual outcomes, frankly, smacks of sociopathy.\n",
      "\n",
      "##BREXITSBANE\n",
      "https://profile.theguardian.com/user/id/100435155\n",
      "\n",
      "Even actual exams aren't an ideal way of grading students.\n",
      "\n",
      "It depends on what you are testing. If you are testing attainment in** MATH**ematics then the traditional examination is a very good way of testing it. If you are testing ability in creative writing, it is a poor way of testing it.\n",
      "\n",
      "##TONDA99\n",
      "https://profile.theguardian.com/user/id/15089465\n",
      "\n",
      "Algorithms, in one form or another, have been around for far longer than I had thought. Here's just one interesting fact from Wikipedia's Algorithm page:\n",
      "\n",
      "The word algorithm itself is derived from the 9th-century** MATH**ematician Muḥammad ibn Mūsā al-Khwārizmī, Latinized Algoritmi.\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "Unfortunately, as has been highlighted recently, very, very few people in the media (especially the guardian) have even a basic understanding of** MATH**s and science. That largely extends to politicians also.\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "I'm not even sure this instance involves anything as complex as the use of what's often called AI, but what you call AI is just** MATH**ematics anyway. \n",
      "Are you suggesting we should stop using** MATH**ematics?\n",
      "\n",
      "##TONDA99\n",
      "https://profile.theguardian.com/user/id/15089465\n",
      "\n",
      "It seems they go even further back than that: \n",
      "\n",
      "Arithmetic algorithms, such as a division algorithm, was used by ancient Babylonian** MATH**ematicians c. 2500 BC and Egyptian** MATH**ematicians c. 1550 BC.\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "What you're describing is the opposite of a** MATH**ematically rigourous algorithmically defined process and outcome. \n",
      "Can I ask if you have a** MATH**s or science background?\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "I agree with your concept -** MATH**s doesn't work for predicting outcomes at the level of the individual - but maybe less so with the political slant you put on it.\n",
      "\n",
      "##WHERESMEHAT\n",
      "https://profile.theguardian.com/user/id/12302661\n",
      "\n",
      "Not being a** MATH**ematician I just think an algorithm is an anonymous wizard somewhere who occasionally inexplicably plays me Tina Turner\n",
      "\n",
      "##TYLERSAYSWAT\n",
      "https://profile.theguardian.com/user/id/4471788\n",
      "\n",
      "Weapons of Math Destruction by Cathy O’Neil is a good starting place if you want to find out how bad algorithms can be.\n",
      "\n",
      "##LEBONCHIEN\n",
      "https://profile.theguardian.com/user/id/18032210\n",
      "\n",
      "Read \"Weapons of Math Destruction: How Bog Data Increases Inequality and Threatens Democracy\" by Cathy O'Neill.\n",
      "\n",
      "##426F6254\n",
      "https://profile.theguardian.com/user/id/15389372\n",
      "\n",
      "It's using** MATH**s as a substitute for making a decision which is the problem. Good servant, bad master.\n",
      "\n",
      "##BREXITSBANE\n",
      "https://profile.theguardian.com/user/id/100435155\n",
      "\n",
      "Algorithms go back all the way to Greek** MATH**ematics. The the Sieve of Eratosthenes, for example.\n",
      "\n",
      "##JDRMCR\n",
      "https://profile.theguardian.com/user/id/101368991\n",
      "\n",
      "If you understood** MATH**s you would know that an algorithm cannot predict WHICH students to downgrade.\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "Yes they didn't use** MATH**s at Bletchley Park or Los Alamos.\n",
      "\n",
      "##FATBOB\n",
      "https://profile.theguardian.com/user/id/2314180\n",
      "\n",
      "Why is it depressing to use** MATH**s to make a decision?\n"
     ]
    }
   ],
   "source": [
    "target = 'decolon'\n",
    "target = 'science'\n",
    "target = ' math'\n",
    "\n",
    "xx = [x for x in all_comments if target.lower() in x.lower() and  len(x) > 20]\n",
    "yy = [x for x in all_comments if '#pin' in x.lower() and 2000 > len(x) > 20]\n",
    "\n",
    "#print('\\n\\n'.join( ['\\n\\n'.join(x) for x in zip(xx,yy)])  )\n",
    "\n",
    "\n",
    "print( '\\n\\n'.join(xx).replace(target, '**'+ target.upper() +'**') )\n",
    "#print( '\\n\\n'.join(xx) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPkernel",
   "language": "python",
   "name": "nlpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
